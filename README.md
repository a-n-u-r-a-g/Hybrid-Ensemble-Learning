# IDS_through_ML_and_DL
Hybrid Ensemble Learning with Explainable AI for Anomaly Detection in Network Traffic

The increasing intricacy and quantity of network 
data pose significant obstacles for anomaly detection systems. 
Detecting and responding appropriately to novel and changing 
dangers is a challenge for conventional approaches. This 
research presents a novel method for explainable AI (XAI)
integrated hybrid ensemble learning for improving real-time 
anomaly detection in network data. The proposed model 
combines many machines learning techniques, including 
Random Forest, deep learning (CNN, Bi-LSTM) and boosting, 
to provide a robust ensemble capable of identifying a wide range 
of irregularities. Furthermore, by employing XAI techniques, 
the model's decisions are rendered in a clear and understandable way, 
encouraging confidence comprehension among cybersecurity specialists. The proposed 
technique is tested on two widespread network traffic datasets: 
CICIDS 2017 and UNSW-NB15. Experimental results 
demonstrate that our model achieves high accuracy rates of 
99.98% and 97.71% on these datasets, respectively, with False 
Positive Rates (FPR) as low as 0.02% and 0.01%. Based on 
experimental out-comes, our model provides a dependable 
solution for network anomaly detection, outperforming current 
state-of-the-art methods in rapports of accuracy, precision, 
recall, and F1-score. 
